import os
import logging
from typing import List, Tuple, Dict, Any
import json
import time
import re
from config import LLAMA_SCOUT_MODEL, TEMPERATURE, MAX_TOKENS, ERROR_MESSAGES

logger = logging.getLogger(__name__)

# Import Cerebras SDK - this is required for production
try:
    from cerebras.cloud.sdk import Cerebras
    CEREBRAS_SDK_AVAILABLE = True
except ImportError as e:
    logger.error(f"Cerebras SDK not available: {str(e)}")
    logger.error("Install with: pip install cerebras-cloud-sdk")
    CEREBRAS_SDK_AVAILABLE = False


def process_with_llama_scout(
    query: str,
    regulation_data: List[str],
    api_key: str
) -> Tuple[str, List[int]]:
    """
    Process regulation data with Llama Scout model via Cerebras API.
    
    Args:
        query: The user's query about automotive regulations
        regulation_data: List of extracted regulation content
        api_key: Cerebras API key
    
    Returns:
        Tuple containing:
            - The answer text generated by the model
            - List of source indices used in the response
    """
    logger.info("Processing regulation data with Llama Scout model")
    
    if not regulation_data:
        logger.error("No regulation data provided for processing")
        raise ValueError(ERROR_MESSAGES["no_data_found"])
    
    if not CEREBRAS_SDK_AVAILABLE:
        logger.error("Cerebras SDK is not available")
        raise Exception("Cerebras SDK is not installed. Run: pip install cerebras-cloud-sdk")
    
    if not api_key or api_key == "YOUR_CEREBRAS_API_KEY":
        logger.error("Cerebras API key not configured")
        raise ValueError(ERROR_MESSAGES["api_key_missing"])
    
    try:
        # Combine all regulation data with source indicators
        context = ""
        for i, data in enumerate(regulation_data):
            context += f"[Source {i}]\n{data}\n\n"
        
        # Create the enhanced prompt for precise regulatory answers
        prompt = create_enhanced_regulatory_prompt(query, context)
        
        # Call the Cerebras API with Llama Scout model
        answer, source_indices = call_cerebras_api(prompt, api_key)
        
        # Validate and enhance the answer
        answer = validate_and_enhance_answer(answer, query)
        
        logger.info(f"Successfully processed with Llama Scout model. Referenced {len(source_indices)} sources.")
        return answer, source_indices
    
    except Exception as e:
        logger.error(f"Error in process_with_llama_scout: {str(e)}")
        raise Exception(f"{ERROR_MESSAGES['cerebras_api_error']}: {str(e)}")


def create_enhanced_regulatory_prompt(query: str, context: str) -> str:
    """
    Create an enhanced prompt for precise regulatory answers.
    
    Args:
        query: The user's query about automotive regulations
        context: Combined regulation data with source indicators
    
    Returns:
        Formatted prompt string for precise regulatory answers
    """
    return f"""You are a Senior Automotive Regulatory Compliance Expert with 25+ years of experience in global vehicle homologation and regulatory affairs. Your expertise covers all major automotive markets including EU, US, Japan, China, and other regions.

REGULATORY SOURCES:
{context}

USER QUESTION: {query}

CRITICAL INSTRUCTIONS:
1. ONLY use information from the provided sources - cite as [Source X]
2. Be PRECISE and SPECIFIC - provide exact requirements, numbers, dates, limits
3. Be CONCISE - focus on directly answering the question without unnecessary background
4. Include specific regulation numbers, standards, or directive references when available
5. State the applicable jurisdiction/region clearly
6. If sources have conflicting information, note the discrepancy with source citations
7. Use bullet points or numbered lists for multiple requirements
8. Include compliance dates, phase-in periods, or deadlines if mentioned
9. Do not add general automotive knowledge not in the sources
10. If the sources don't contain enough information to answer, say "The provided sources do not contain sufficient information to fully answer this question"

ANSWER FORMAT:
- Start with a direct answer to the question
- Provide specific regulatory details with source citations
- Include applicable regions/markets
- List key requirements or limits if relevant
- End with any compliance dates or important notes

ANSWER:"""


def call_cerebras_api(prompt: str, api_key: str) -> Tuple[str, List[int]]:
    """
    Call the Cerebras API with the Llama Scout model.
    
    Args:
        prompt: The formatted prompt
        api_key: Cerebras API key
    
    Returns:
        Tuple containing:
            - The answer text generated by the model
            - List of source indices used in the response
    """
    if not CEREBRAS_SDK_AVAILABLE:
        raise Exception("Cerebras SDK is not available")
    
    try:
        client = Cerebras(api_key=api_key)
        
        # Call the Cerebras API with enhanced parameters for precision
        response = client.chat.completions.create(
            messages=[
                {"role": "user", "content": prompt}
            ],
            model=LLAMA_SCOUT_MODEL,
            temperature=0.1,  # Low temperature for precise, consistent answers
            max_tokens=1500,  # Reduced for more concise answers
            top_p=0.9
        )
        
        # Extract the generated text
        answer = response.choices[0].message.content
        
        # Extract source indices from the response
        source_indices = extract_source_indices(answer)
        
        # Validate that the response contains source references
        if not source_indices:
            logger.warning("LLM response did not reference any sources")
            # Try to infer which sources might be relevant based on content overlap
            source_indices = [0]  # Default to first source if no citations found
        
        return answer, source_indices
        
    except Exception as e:
        logger.error(f"Error calling Cerebras API: {str(e)}")
        raise Exception(f"Cerebras API error: {str(e)}")


def validate_and_enhance_answer(answer: str, query: str) -> str:
    """
    Validate and enhance the regulatory answer for quality and compliance.
    
    Args:
        answer: The LLM's response
        query: The original query
    
    Returns:
        Enhanced answer with proper disclaimers
    """
    # Check if answer is too generic or unhelpful
    if len(answer.strip()) < 100:
        answer += "\n\n*Note: Limited information was available in the provided regulatory sources for this specific query.*"
    
    # Add regulatory disclaimer
    disclaimer = """

**⚖️ Regulatory Disclaimer:**
This information is based on available regulatory sources and may not reflect the most current regulations. Always verify with official regulatory authorities and consult qualified automotive compliance experts for legal compliance decisions."""
    
    # Clean up the answer
    answer = clean_regulatory_answer(answer)
    
    return answer + disclaimer


def clean_regulatory_answer(answer: str) -> str:
    """
    Clean up the regulatory answer for better presentation.
    
    Args:
        answer: Raw answer from LLM
    
    Returns:
        Cleaned answer
    """
    # Remove excessive line breaks
    answer = re.sub(r'\n{3,}', '\n\n', answer)
    
    # Fix spacing around bullet points
    answer = re.sub(r'\n\s*[-*•]\s*', '\n• ', answer)
    
    # Fix spacing around numbered lists
    answer = re.sub(r'\n\s*(\d+)\.\s*', r'\n\1. ', answer)
    
    # Ensure proper spacing after source citations
    answer = re.sub(r'\[Source\s+\d+\]\s*([A-Z])', r'[Source \1] \2', answer)
    
    # Remove redundant whitespace
    answer = re.sub(r' +', ' ', answer)
    
    return answer.strip()


def extract_source_indices(text: str) -> List[int]:
    """
    Extract source indices referenced in the model's response.
    
    Args:
        text: The model's response text
    
    Returns:
        List of source indices
    """
    import re
    
    # Find all instances of [Source X] in the text
    matches = re.findall(r'\[Source\s+(\d+)\]', text)
    
    # Convert matches to integers and remove duplicates
    source_indices = list(set(int(match) for match in matches))
    
    return sorted(source_indices)


def extract_regulatory_specifics(response: str) -> Dict[str, List[str]]:
    """
    Extract specific regulatory information from the response.
    
    Args:
        response: The LLM response
    
    Returns:
        Dictionary containing extracted regulatory specifics
    """
    specifics = {
        "regulation_numbers": [],
        "limits": [],
        "dates": [],
        "regions": []
    }
    
    # Extract regulation numbers (e.g., ECE-R100, 2018/858/EU, FMVSS 208)
    reg_numbers = re.findall(r'(?:ECE-R|FMVSS|EU|Regulation|Directive)\s*[№#]?\s*[\d/]+[A-Z]*', response, re.IGNORECASE)
    specifics["regulation_numbers"] = list(set(reg_numbers))
    
    # Extract numerical limits (e.g., 80 mg/km, 5.0 g/test)
    limits = re.findall(r'\d+(?:\.\d+)?\s*(?:mg/km|g/test|dB|%|ppm|bar|kPa)', response)
    specifics["limits"] = list(set(limits))
    
    # Extract dates (various formats)
    dates = re.findall(r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\s+\d{1,2},?\s+\d{4}|\d{1,2}[/-]\d{1,2}[/-]\d{2,4}|\d{4}[/-]\d{1,2}[/-]\d{1,2}', response)
    specifics["dates"] = list(set(dates))
    
    # Extract regions/jurisdictions
    regions = re.findall(r'\b(?:EU|European Union|US|United States|Japan|China|UK|United Kingdom|India|Australia|Global|International)\b', response, re.IGNORECASE)
    specifics["regions"] = list(set([r.upper() for r in regions]))
    
    return specifics


def format_regulatory_response(answer: str, source_indices: List[int], regulation_specifics: Dict[str, List[str]]) -> str:
    """
    Format the regulatory response with enhanced structure.
    
    Args:
        answer: The main answer
        source_indices: List of source indices used
        regulation_specifics: Extracted regulatory specifics
    
    Returns:
        Formatted response
    """
    formatted_response = answer
    
    # Add summary of regulatory specifics if they exist
    if any(regulation_specifics.values()):
        summary_parts = []
        
        if regulation_specifics["regulation_numbers"]:
            summary_parts.append(f"**Regulations Referenced:** {', '.join(regulation_specifics['regulation_numbers'][:3])}")
        
        if regulation_specifics["regions"]:
            summary_parts.append(f"**Jurisdictions:** {', '.join(regulation_specifics['regions'][:3])}")
        
        if regulation_specifics["limits"]:
            summary_parts.append(f"**Key Limits:** {', '.join(regulation_specifics['limits'][:3])}")
        
        if summary_parts:
            formatted_response += "\n\n---\n**Quick Reference:**\n" + "\n".join(summary_parts)
    
    return formatted_response
